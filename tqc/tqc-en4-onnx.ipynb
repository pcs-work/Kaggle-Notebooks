{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%bash\npip install timm onnx onnxruntime -q","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":16.821079,"end_time":"2023-09-08T22:30:16.188578","exception":false,"start_time":"2023-09-08T22:29:59.367499","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport cv2\nimport json\nimport onnx\nimport timm\nimport torch\nimport random as r\nimport numpy as np\nimport pandas as pd\nimport onnxruntime as ort\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom typing import Union\nfrom torchvision import models\nfrom IPython.display import clear_output\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nif not os.path.exists(\"onnx\"): os.makedirs(\"onnx\")\n    \nort.set_default_logger_severity(3)","metadata":{"papermill":{"duration":7.261033,"end_time":"2023-09-08T22:30:23.455706","exception":false,"start_time":"2023-09-08T22:30:16.194673","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels: dict = json.load(open(\"/kaggle/input/tqc-dataframe/labels.json\", \"r\"))\n    \n    \ndef breaker() -> None:\n    print(\"\\n\" + 50*\"*\" + \"\\n\")\n\n    \ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\n\ndef get_image(path: str, size: int=224) -> np.ndarray:\n    image = cv2.imread(path, cv2.IMREAD_COLOR)\n    image = cv2.cvtColor(src=image, code=cv2.COLOR_BGR2RGB)\n    return cv2.resize(src=image, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n    \n\ndef show_image(\n    image: np.ndarray, \n    cmap: str=\"gnuplot2\", \n    title: Union[str, None]=None\n) -> None:\n    plt.figure()\n    plt.imshow(image, cmap=cmap)\n    plt.axis(\"off\")\n    if title: plt.title(title)\n    plt.show()","metadata":{"papermill":{"duration":0.034037,"end_time":"2023-09-08T22:30:23.495595","exception":false,"start_time":"2023-09-08T22:30:23.461558","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(torch.nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        \n        self.model = timm.create_model(\n            model_name=\"efficientnet_b4\", \n            pretrained=False\n        )\n        self.model.classifier = torch.nn.Linear(\n            in_features=self.model.classifier.in_features, \n            out_features=1\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n    \nclass CFG(object):  \n    def __init__(\n        self, \n        in_channels: int=3, \n        size: int=256, \n        opset_version: int=9, \n        path: str=None\n    ):\n        self.in_channels = in_channels\n        self.size = size\n        self.dummy = torch.randn(1, self.in_channels, self.size, self.size)\n        self.opset_version = opset_version\n        self.path = path","metadata":{"papermill":{"duration":0.023219,"end_time":"2023-09-08T22:30:23.524555","exception":false,"start_time":"2023-09-08T22:30:23.501336","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fold 4 (BEST), Fold 2 (SECOND BEST), Fold 5 (THIRD BEST)\n\nfor fold in range(1, 6):\n    for v in [\"a\", \"l\"]:\n        cfg = CFG(\n            in_channels=3, \n            size=224, \n            opset_version=15, \n            path=f\"/kaggle/input/tqc-en4-a224-e10-f{fold}/saves/b{v}e_state_fold_{fold}.pt\"\n        )\n\n        model = Model()\n        model.load_state_dict(torch.load(cfg.path, map_location=torch.device(\"cpu\"))[\"model_state_dict\"])\n        model.eval()\n\n        clear_output()\n\n        torch.onnx.export(\n            model=model, \n            args=cfg.dummy, \n            f=f\"onnx/b{v}e_model_f{fold}.onnx\", \n            input_names=[\"input\"], \n            output_names=[\"output\"], \n            opset_version=cfg.opset_version,\n            export_params=True,\n            training=torch.onnx.TrainingMode.EVAL,\n            operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,\n            dynamic_axes={\n              \"input\"  : {0 : \"batch_size\"},\n              \"output\" : {0 : \"batch_size\"},\n            }\n        )","metadata":{"papermill":{"duration":79.984934,"end_time":"2023-09-08T22:31:43.515331","exception":false,"start_time":"2023-09-08T22:30:23.530397","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OnnxModel(object):\n    def __init__(self, path: str) -> None:\n        self.size: int = 224\n        \n        self.mean: list = [0.47522, 0.47488, 0.47371]\n        self.std: list  = [0.14752, 0.14700, 0.14985]\n        \n        self.path: str = path\n    \n        model = onnx.load(self.path)\n        onnx.checker.check_model(model)\n        self.ort_session = ort.InferenceSession(\n            self.path, \n            providers=['CUDAExecutionProvider', 'CPUExecutionProvider'],\n        )\n        \n    def infer(self, image: np.ndarray, labels: dict) -> np.ndarray:\n        image = image / 255\n        image = image.transpose(2, 0, 1)\n        for i in range(image.shape[0]): image[i, :, :] = (image[i, :, :] - self.mean[i]) / self.std[i]\n        image = np.expand_dims(image, axis=0)\n        inputs = {self.ort_session.get_inputs()[0].name: image.astype(\"float32\")}\n        prob = sigmoid(self.ort_session.run(None, inputs)[0][0])\n        if prob <= 0.5:\n            return \"Defective\", 1-prob\n        else:\n            return \"Good\", prob","metadata":{"papermill":{"duration":0.021539,"end_time":"2023-09-08T22:31:43.542720","exception":false,"start_time":"2023-09-08T22:31:43.521181","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tqc-dataframe/test.csv\")\n\nbreaker()\nfor model_name in sorted(os.listdir(\"onnx\")):\n    \n    onnx_model = OnnxModel(f\"onnx/{model_name}\")\n    \n    print(f\"{model_name.upper()}\\n\")\n    \n    count: int = 0\n    \n    for i in range(20):\n        index = r.randint(0, len(df)-1)\n        filepath = df.iloc[index, 0]\n        y_true   = df.iloc[index, 1]\n\n        image = get_image(filepath)\n\n        y_pred, _ = onnx_model.infer(image, labels)\n        \n        if labels[str(y_true)] == y_pred:\n            count += 1\n        \n        print(f\"{labels[str(y_true)]}, {y_pred}\")\n        # show_image(image, title=y_pred)\n    \n    print(f\"\\n\\nAccuracy : {count / 20:.5f}\")\n\n    breaker()","metadata":{"papermill":{"duration":38.384439,"end_time":"2023-09-08T22:32:21.932884","exception":false,"start_time":"2023-09-08T22:31:43.548445","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}